from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F

# Carregar tokenizador e modelos
tokenizer = AutoTokenizer.from_pretrained("roberta-base")
model_base = AutoModelForSequenceClassification.from_pretrained("roberta-base", num_labels=2)
model_tuned = AutoModelForSequenceClassification.from_pretrained("PirateXX/AI-Content-Detector")

# Texto de exemplo
text = "This text is generated by AI."

# Tokenizar entrada
inputs = tokenizer(text, return_tensors="pt")

# Obter previsÃµes dos dois modelos
logits_base = model_base(**inputs).logits
logits_tuned = model_tuned(**inputs).logits

# Aplicar softmax para obter probabilidades
probs_base = F.softmax(logits_base, dim=-1)
probs_tuned = F.softmax(logits_tuned, dim=-1)

# Mostrar resultados
print(f"ðŸ”¹ Modelo Base (roberta-base): {probs_base}")
print(f"âœ… Modelo Fine-Tunado: {probs_tuned}")
